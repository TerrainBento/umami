{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Other options for input\n",
    "\n",
    "Umami is a package for calculating metrics for use with for Earth surface dynamics models. This notebook is the final notebook in a three-part introduction to using umami.\n",
    "\n",
    "Umami was designed to work well with the [terrainbento](https://terrainbento.readthedocs.io/en/latest/) model package, as well as other models built using the [Landlab Toolkit](https://github.com/landlab/landlab). However, umami can be used with models built with other modeling tools and data in a variety of formats. \n",
    "\n",
    "## Scope of this tutorial\n",
    "\n",
    "In this tutorial you will learn how to use other input options for umami. \n",
    "\n",
    "Specifically we will use square gridded terrain stored as a [netCDF](https://www.unidata.ucar.edu/software/netcdf/).\n",
    "\n",
    "If you have comments or questions about the notebooks, the best place to get help is through [GitHub Issues](https://github.com/TerrainBento/umami/issues).\n",
    "\n",
    "To begin this example, we will import the required python packages. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.interpolate import interp2d\n",
    "\n",
    "from urllib.request import urlopen\n",
    "from io import BytesIO, StringIO\n",
    "\n",
    "from landlab import imshow_grid, RasterModelGrid, VoronoiDelaunayGrid\n",
    "from landlab.io import read_esri_ascii\n",
    "\n",
    "from umami import Metric, Residual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Umami does not make any requirements regarding where terrain data comes from or what model or modeling package is used to construct modeled terrain. However, umami does require that modeled or observed terrain is provided to it as a Landlab grid with an at-node field called `topographic__elevation`. \n",
    "\n",
    "This requirement means that umami can take advantage of Landlab's [existing functions for input](https://landlab.readthedocs.io/en/release/landlab.io.html). Additionally, a Landlab grid can take a field based on a [numpy array](https://docs.scipy.org/doc/numpy/reference/generated/numpy.array.html). Thus any file format you can read into python as a numpy array can be used as a landlab grid. \n",
    "\n",
    "## Step 1: Read in and use a numpy array\n",
    "\n",
    "In this example we will download data from the [OpenTopography REST server](https://opentopography.org/developers). We will download a small patch of land near Boulder, CO. You can change the values of `north`, `south`, `east` and `west` to change the location. \n",
    "\n",
    "These data are provided with horizontal units of degrees. For this example we will ignore "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "west=-105.35 # longitude (degrees)\n",
    "east=-105.15 # longitude (degrees)\n",
    "north=40.1 # latitude (degrees)\n",
    "south=39.9 # latitue (degrees)\n",
    "\n",
    "URL = \"http://opentopo.sdsc.edu/otr/getdem?demtype=SRTMGL3&\"\n",
    "url = (URL + \n",
    "           \"west=\" + str(west) + \"&\" +\n",
    "           \"south=\" + str(south) + \"&\"\n",
    "           \"east=\" + str(east) + \"&\"\n",
    "           \"north=\" + str(north) + \"&\"\n",
    "           \"outputFormat=AAIGrid\")\n",
    "\n",
    "f = urlopen(url)\n",
    "b = BytesIO(f.read())\n",
    "file_like = StringIO(b.getvalue().decode(\"UTF-8\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use Landlab IO functions to read.\n",
    "    \n",
    "    \n",
    "You could do this with gdal, or rasterio, or whatever you like... at the end of the day, we just care about z being a numpy array..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mg, z = read_esri_ascii(file_like, name=\"topographic__elevation\")\n",
    "imshow_grid(mg, z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "z is just a numpy array. We can create a new grid and add a random numpy field to it. \n",
    "\n",
    "But Umami will care that the grids are the same. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?read_esri_ascii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mg.dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mg.xy_of_lower_left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_mg = RasterModelGrid(mg.shape, mg.dx, xy_of_lower_left=mg.xy_of_lower_left)\n",
    "new_z = new_mg.add_field(\"node\", \"topographic__elevation\", z + np.random.randn(z.size))\n",
    "imshow_grid(new_mg, new_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow_grid(new_mg, new_z-z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = {\n",
    "    \"me\": {\n",
    "        \"_func\": \"aggregate\",\n",
    "        \"method\": \"mean\",\n",
    "        \"field\": \"topographic__elevation\"\n",
    "    },\n",
    "    \"ep10\": {\n",
    "        \"_func\": \"aggregate\",\n",
    "        \"method\": \"percentile\",\n",
    "        \"field\": \"topographic__elevation\",\n",
    "        \"q\": 10\n",
    "    }\n",
    "}\n",
    "residual = Residual(new_mg, mg, residuals=residuals)\n",
    "residual.calculate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residual.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residual.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Use irregular data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp_obj = interp2d(mg.x_of_node, mg.y_of_node, z)\n",
    "\n",
    "random_x = np.random.uniform(low=mg.x_of_node.min(), high=mg.x_of_node.max(), size=mg.x_of_node.size)\n",
    "random_y = np.random.uniform(low=mg.y_of_node.min(), high=mg.y_of_node.max(), size=mg.y_of_node.size)\n",
    "\n",
    "interp_z = interp_obj(random_x, random_z)\n",
    "\n",
    "# going to need to re-order so that there isn't an issue. Could also just nudge each xy point around a little. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vdg = VoronoiDelaunayGrid(random_x, random_y)\n",
    "vdg.add_field(\"node\", \"topographic__elevation\", interp_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {\n",
    "    \"me\": {\n",
    "        \"_func\": \"aggregate\",\n",
    "        \"method\": \"mean\",\n",
    "        \"field\": \"topographic__elevation\"\n",
    "    },\n",
    "    \"ep10\": {\n",
    "        \"_func\": \"aggregate\",\n",
    "        \"method\": \"percentile\",\n",
    "        \"field\": \"topographic__elevation\",\n",
    "        \"q\": 10\n",
    "    }\n",
    "}\n",
    "\n",
    "metric = Metric(vdg, metrics=metrics)\n",
    "metric.calculate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next steps\n",
    "\n",
    "Now that you have a sense for how the `Metric` and `Residual` classes are used, try the next notebook: [Part 4: Example application](ExampleApplication.ipynb)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
