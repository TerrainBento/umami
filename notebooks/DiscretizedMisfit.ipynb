{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4: Application using the Discretized Misfit calculation\n",
    "\n",
    "\n",
    "By now, you should have looked through [Part 1](IntroductionToMetric.ipynb) and [Part 2](IntroductionToResidual.ipynb) of the introductory notebook series. These introduced the umami `Metric` and `Residual` classes. You should have also worked through [Part 3](ExampleApplication.ipynb), which provides an example application of umami. \n",
    "\n",
    "## Scope\n",
    "\n",
    "Similar to [Part 3](ExampleApplication.ipynb), this application will use umami alongside the [terrainbento](https://terrainbento.readthedocs.io/en/latest/) package. As in the prior example, we will define a \"synthetic truth\" model evaluation with a specific set of input parameters, and then do a grid search letting some of those parameters vary. In this way we will explore which statistics for model-data comparison do best at identifying the \"true\" parameters. \n",
    "\n",
    "This application focuses on the least intuitive of the umami calculations: the [`discretized_misfit`](https://umami.readthedocs.io/en/latest/umami.calculations.residual.discretized_misfit.html). \n",
    "\n",
    "If you have comments or questions about the notebooks, the best place to get help is through [GitHub Issues](https://github.com/TerrainBento/umami/issues).\n",
    "\n",
    "To begin, we import necessary modules. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from io import StringIO\n",
    "from itertools import product\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from plotnine import *\n",
    "\n",
    "import holoviews as hv\n",
    "hv.notebook_extension('matplotlib')\n",
    "\n",
    "from landlab import imshow_grid\n",
    "from terrainbento import Basic\n",
    "from umami import Metric, Residual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin by defining an input string that defines the terrainbento model.\n",
    "\n",
    "It evolves topography using stream power and linear diffusion. In our application it has a boundary condition of uniform uplift across the core of the model grid. It thus has the following governing equation:\n",
    "\n",
    "$\\frac{\\partial \\eta}{\\partial t} = U - KQ^{1/2}S + D\\nabla^2 \\eta$\n",
    "\n",
    "where $K$ and $D$ are constants, $Q$ is discharge, $S$ is local slope, $U$ is the uplift rate, and $\\eta$ is the topography. See the [model Basic documentation](https://terrainbento.readthedocs.io/en/latest/source/terrainbento.derived_models.model_basic.html) for additional information. \n",
    "\n",
    "In this input file we also indicate that the model will run with timesteps of 500 yr and the model grid will have a shape of (50, 80), with grid cell spacing of 100 m. For this application, the model initial condition is for core nodes to have random noise added.\n",
    "\n",
    "A few places in the input file have curly braces around a name. \n",
    "* Two inputs parameters have curly brackets around them: `{duration}` and `{water_erodibility}`. These inputs will be modified using [`str.format`](https://docs.python.org/3/library/stdtypes.html#str.format) to set the \"truth\" model run and to vary the parameters in a grid search numerical experiment. \n",
    "* We also format the `{name}` of output files in order to prevent Windows file permissions errors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_string = \"\"\"\n",
    "# Create the Clock.\n",
    "clock:\n",
    "    start: 0\n",
    "    step: 500\n",
    "    stop: {duration}\n",
    "\n",
    "# Create the Grid\n",
    "grid: \n",
    "    RasterModelGrid: \n",
    "        - [100, 120]\n",
    "        - xy_spacing: 50\n",
    "        - fields: \n",
    "            node: \n",
    "                topographic__elevation:\n",
    "                    random:\n",
    "                        where: CORE_NODE\n",
    "\n",
    "                        \n",
    "# Set up Boundary Handlers\n",
    "boundary_handlers: \n",
    "    NotCoreNodeBaselevelHandler: \n",
    "        modify_core_nodes: True\n",
    "        lowering_rate: -{lowering_rate}\n",
    "\n",
    "# Parameters that control output.\n",
    "output_interval: 1e3\n",
    "save_first_timestep: True\n",
    "output_prefix: \n",
    "    disc_resid.{name}.\n",
    "fields: \n",
    "    - topographic__elevation\n",
    "\n",
    "# Parameters that control process and rates.\n",
    "water_erodibility: {water_erodibility}\n",
    "m_sp: 0.5\n",
    "n_sp: 1.0\n",
    "regolith_transport_parameter: 0.1\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we instantiate the \"truth\" model and run it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truth_duration = 3e4\n",
    "truth_water_erodibility = 0.0005\n",
    "\n",
    "lowering_rate = 100 / truth_duration\n",
    "\n",
    "truth_params = StringIO(\n",
    "    spec_string.format(duration=truth_duration,\n",
    "                       water_erodibility=truth_water_erodibility,\n",
    "                       lowering_rate=lowering_rate,\n",
    "                       name=\"truth\"))\n",
    "np.random.seed(42)\n",
    "truth = Basic.from_file(truth_params)\n",
    "truth.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [holoviews](https://holoviews.org) package provides capabilities to visualize the model run. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = truth.to_xarray_dataset(time_unit='years', space_unit='meters')\n",
    "hvds_topo = hv.Dataset(ds.topographic__elevation)\n",
    "topo = hvds_topo.to(hv.Image, ['x', 'y'],\n",
    "                    label='Truth').options(interpolation='bilinear',\n",
    "                                           cmap='viridis',\n",
    "                                           colorbar=True)\n",
    "topo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the center nodes are uplifted, a series of ridges and drainage basins form. This model has not yet reached \"topographic steady state\", in which $\\frac{\\partial \\eta}{\\partial t}>\\epsilon$ (and $\\epsilon$ is small) everywhere. \n",
    "\n",
    "Before moving on, we close the xarray dataset and remove the output netcdf files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.close()\n",
    "truth.remove_output_netcdfs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Define the basis for model-data comparison\n",
    "\n",
    "The discretized_misfit takes the following parameters:\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model_grid : Landlab model grid\n",
    "    data_grid : Landlab model grid\n",
    "    name : str\n",
    "    misfit_field : str\n",
    "    field_1 : str\n",
    "    field_2 : str\n",
    "    field_1_percentile_edges : list\n",
    "    field_2_percentile_edges : list\n",
    "    \n",
    "This calculation first classifies each grid cell in the landscape into categories based on `field_1`, `field_2` and the percentile edges for each (using the data grid). This results in a set of categories, which may or may not be contiguous in space. \n",
    "\n",
    "For each category, the sum of squared residuals is calculated based on the misfit_field.\n",
    "\n",
    "Since this calculation returns one value for each category, rather than one value in total, a `name` must be provided. This is a string that will be formatted with the values for `{field_1_level}` and `{field_2_level}`. The output is an ordered dictionary with name as the keys, and the sum of squares misfit as the values.\n",
    "\n",
    "The following is the input file (as string) needed to specify a `discretized_misfit` in which the domain is discretized based on `channel__chi_index` (three percentile levels defined by `[0, 30, 60, 100]`), and `topographic__elevation` (two percentile levels defined by `[0, 50, 100]`). \n",
    "\n",
    "Within each of the six category domains, a misfit is made based on the field `topographic__elevation`. \n",
    "\n",
    "Below we will show a plot indicating where each category is located, but first we will specify the numerical experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residual_string = \"\"\"\n",
    "dm:\n",
    "    _func: discretized_misfit\n",
    "    name: chi_{field_1_level}.z_{field_2_level}\n",
    "    misfit_field: topographic__elevation\n",
    "    field_1: channel__chi_index\n",
    "    field_2: topographic__elevation\n",
    "    field_1_percentile_edges:\n",
    "        - 0\n",
    "        - 30\n",
    "        - 60\n",
    "        - 100\n",
    "    field_2_percentile_edges:\n",
    "        - 0\n",
    "        - 50\n",
    "        - 100\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Create and run the grid search experiment\n",
    "\n",
    "We will use a grid search to highlight how the misfit values in the `discretized_residual` calculated by umami vary across parameter space. \n",
    "\n",
    "We consider values for `duration` between $10^{3}$ and $10^{5}$ and values for $K$ (`water_erodibility`) between $10^{-4}$ and $10^{-2}$.\n",
    "\n",
    "With a resolution of 10, we evaluate $10^2=100$ simulations. Feel free to change the resolution value, though note that it will impact the run time of this notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resolution = 10\n",
    "durations = np.logspace(3, 5, num=resolution)\n",
    "water_erodibilitys = np.logspace(-4, -2, num=resolution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We evaluate each pair of duration and water erodability and save the model output as a dictionary. With the line \n",
    "\n",
    "    #np.random.seed(42)\n",
    "\n",
    "commented out, each evaluation uses a different random seed. Feel free to uncomment this line to see how the results change if the *exact same* random seed is used for each model integration. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = {}\n",
    "for i, (duration,\n",
    "        water_erodibility) in enumerate(product(durations,\n",
    "                                                water_erodibilitys)):\n",
    "    lowering_rate = 100 / duration\n",
    "    test_params = StringIO(\n",
    "        spec_string.format(duration=duration,\n",
    "                           water_erodibility=water_erodibility,\n",
    "                           lowering_rate=lowering_rate,\n",
    "                           name=i))\n",
    "    #np.random.seed(42)\n",
    "    test = Basic.from_file(test_params)\n",
    "    test.run()\n",
    "\n",
    "    test.remove_output_netcdfs()\n",
    "\n",
    "    residual = Residual(test.grid,\n",
    "                        truth.grid,\n",
    "                        chi_finder_kwds={\"min_drainage_area\": 1000})\n",
    "    residual.add_from_file(StringIO(residual_string))\n",
    "    residual.calculate()\n",
    "\n",
    "    values = {name: residual.value(name) for name in residual.names}\n",
    "    out[(duration, water_erodibility)] = values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before looking at the results, let's inspect the residual class. \n",
    "\n",
    "The property `residual.names` has a name for for each of the six categories. The temporary strings `{field_1_level}` and `{field_2_level}` have been replaced with actual levels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residual.names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The property `residual.values` has one value for each of the six categories. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residual.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot the category using the `residual.category` property. Here each category gets its own panel. For example, the leftmost column represents the cells with `channel__chi_index` values in the lower 30%. The upper left panel is those that have the lower half of elevation values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 3, dpi=150)\n",
    "\n",
    "for i, name in enumerate(residual.names):\n",
    "    col, row = np.unravel_index(i, (3,2))\n",
    "    plt.sca(axes[row, col])\n",
    "    imshow_grid(truth.grid, residual.category==(i+1), cmap=\"cividis\", allow_colorbar=False)\n",
    "    plt.title(name)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.xlabel(None)\n",
    "    plt.ylabel(None)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we compile the output into a pandas dataframe and inspect. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(out, orient=\"index\")\n",
    "df.index.names = [\"duration\", \"water_erodibility\"]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to the earlier notebook, we melt this dataframe in order to plot it. We also rename the column \"value\" to \"sum_of_squared_residuals\", as this is what `discretized_misfit` calculates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_melt = df.reset_index().melt(id_vars=[\"duration\", \"water_erodibility\"])\n",
    "df_melt = df_melt.rename(columns={\"value\": \"sum_of_squared_residuals\"})\n",
    "df_melt.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also use the [string.split](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.str.split.html) pandas function in order to turn our variable name into two columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_split = df_melt[\"variable\"].str.split(\".\", n=1, expand=True)\n",
    "df_melt[\"chi\"] = variable_split[0]\n",
    "df_melt[\"elev\"] = variable_split[1]\n",
    "df_melt.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we plot the squared residual as a function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = (ggplot(df_melt,\n",
    "             aes(x=\"duration\", y=\"water_erodibility\",\n",
    "                 fill=\"sum_of_squared_residuals\")) + geom_tile() +\n",
    "      geom_point(aes(x=truth_duration, y=truth_water_erodibility)) +\n",
    "      scale_fill_continuous(limits=[1, 100], trans=\"log10\") +\n",
    "      facet_grid(\"elev~chi\") + theme_bw() + scale_x_log10() + scale_y_log10() +\n",
    "      coord_equal())\n",
    "print(p1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that the magnitude and \n",
    "\n",
    "# Next Steps\n",
    "Contratulations on finishing the four part series of introductory notebooks. The next steps are to use umami in your own application. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
